
# ğŸ¦¾ Protogen Thought Display System

A modular Raspberry Pi-based animation and subtitle system built for live display via visor, helmet, or glasses-mounted HUD. Uses offline voice recognition to trigger animations and display real-time subtitles in a stylized cyberpunk aesthetic.

## ğŸš€ Features

- ğŸ™ï¸ Offline voice recognition using [Vosk](https://alphacephei.com/vosk/)
- ğŸï¸ Keyword-triggered animation playback via `mpv`
- ğŸ§  Real-time subtitles displayed on screen (with cyberpunk styling)
- ğŸ”„ Idle animations after periods of silence
- ğŸ§  Quirky personality messages when quiet
- ğŸ›ï¸ System launches all components automatically (C++ HUD + Python recognizer)
- ğŸ¨ Cyberpunk aesthetic with colored terminal feedback

## ğŸ› ï¸ Components

- `main.cpp`: Central HUD control loop
- `animation_manager.*`: Loads and plays categorized animations
- `speech_recognizer.py`: Vosk-powered recognizer that sends triggers/subtitles
- `SBOM`: System design and implementation plan

## ğŸ§© File Structure

```
visor/
â”œâ”€â”€ animations/            # GIFs and WebPs organized by trigger word
â”‚   â”œâ”€â”€ hello/
â”‚   â”œâ”€â”€ idle/
â”‚   â””â”€â”€ loading/
|__ model/
â”œâ”€â”€ recognizer/            # Python Vosk recognizer
â”‚   â””â”€â”€ speech_recognizer.py
â”œâ”€â”€ src/                   # C++ components
â”‚   â”œâ”€â”€ main.cpp
â”‚   â”œâ”€â”€ animation_manager.cpp
â”‚   â”œâ”€â”€ animation_manager.h
â”‚   â””â”€â”€ ...
â”œâ”€â”€ messages.txt           # Optional quirky messages (one per line)
â”œâ”€â”€ SBOM                   # Design document
â””â”€â”€ README.md              # This file
```

## ğŸ”§ Setup Instructions

1. Clone the repo:
   ```bash
   git clone https://github.com/h4rml3ss-actual/protogen-thought-display.git
   ```

2. Build the C++ HUD:
   ```bash
   cd visor
   g++ -std=c++17 -Wall -pthread \
       src/main.cpp src/animation_manager.cpp \
       -o build/visor
   ```

3. Make sure your `animations/` folder is populated with GIF or WebP files.

4. Start the HUD:
   ```bash
   ./build/visor
   ```

> âš ï¸ Make sure `model` folder exists for Vosk recognizer (`vosk-model-small-en-us-0.15` or similar)

## ğŸ’¬ Subtitles & Trigger Logic

- Subtitles are streamed from the Python process over a named pipe and rendered as HUD overlays.
- Words matching folder names in `animations/` will trigger playback.

## ğŸ“¦ Dependencies

- `OpenCV`
- `mpv`
- `Python 3` with `vosk`, `sounddevice`

## ğŸ”® Future Ideas

- Add gesture control input
- System metrics (CPU temp, net usage) overlay
- Real-time audio visualizer sync
